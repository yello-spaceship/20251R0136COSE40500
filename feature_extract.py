# -*- coding: utf-8 -*-
"""feature_extract.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QprrtBqTs_R1g5BFZVP2adsG_NJeu0ns

# initial setting
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/cnn_feature/

!pip install torch torchvision Pillow

"""# 이미지 전처리 및 불러오기

"""

from torchvision import transforms

# 이미지 전처리 함수 정의
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

"""# REsNet

"""

import torch
from torchvision import models, transforms
from PIL import Image
from torchvision import models

# 이미지 폴더 경로 설정
img_folder = '/content/drive/MyDrive/cnn_feature/dataset/train/cat'

import torch
from torchvision import models

# 사전 학습된 ResNet 모델 불러오기
model = models.resnet50(pretrained=True)
modules = list(model.children())[:-1]  # 마지막 FC Layer 제거
model = torch.nn.Sequential(*modules)
model.eval()

from PIL import Image
import os
import numpy as np

# 이미지 전처리 및 특징 추출 함수 정의
def extract_features(image_path, model, preprocess):
    img = Image.open(image_path).convert('RGB')
    img_tensor = preprocess(img)
    img_tensor = img_tensor.unsqueeze(0)  # 배치 차원 추가

    with torch.no_grad():
        features = model(img_tensor)
        features = features.squeeze()  # 배치 차원 제거
    return features.numpy()  # NumPy 배열로 변환

import pandas as pd

# 이미지 폴더 경로 설정
output_csv = '/content/drive/MyDrive/cnn_feature/dataset/train/cat/feature/features.csv'

# 데이터프레임 생성
features_list = []
filenames = []

# 이미지 폴더 내 모든 이미지 처리
for filename in os.listdir(img_folder):
    if filename.endswith('.jpg') or filename.endswith('.png'):
        img_path = os.path.join(img_folder, filename)
        features = extract_features(img_path, model, preprocess)

        # 파일 이름과 특징 벡터를 리스트에 저장
        filenames.append(filename)
        features_list.append(features)

        print(f'Processed {filename}, Feature shape: {features.shape}')

# DataFrame으로 변환
features_df = pd.DataFrame(features_list)
features_df.insert(0, 'filename', filenames)

# CSV 파일로 저장
features_df.to_csv(output_csv, index=False)

print(f'Features saved to {output_csv}')



"""# 시각화

"""

import pandas as pd

# CSV 파일 로드
features_df = pd.read_csv('/content/drive/MyDrive/cnn_feature/dataset/train/cat/feature/features.csv')

# 파일 이름과 특징 벡터 분리
filenames = features_df['filename']
features = features_df.drop('filename', axis=1)

print(filenames.head())
print(features.head())

import numpy as np

# 가상의 라벨 생성
labels = np.random.randint(4, size=len(features))  # 이진 분류 예제

# 데이터셋 분할
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# 모델 학습
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

# 예측
y_pred = clf.predict(X_test)

# 평가
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
print('Classification Report:')
print(classification_report(y_test, y_pred))
print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred))

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# K-means 군집화
kmeans = KMeans(n_clusters=2, random_state=42)
kmeans.fit(features)

# 군집화 결과
clusters = kmeans.labels_

# 군집화 결과 시각화
plt.scatter(features.iloc[:, 0], features.iloc[:, 1], c=clusters, cmap='viridis')
plt.title('Clustering of Images based on Features')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.show()

from sklearn.metrics.pairwise import cosine_similarity

# 특정 이미지의 특징 벡터 선택 (예: 첫 번째 이미지)
query_feature = features.iloc[0].values.reshape(1, -1)

# 모든 이미지와의 유사도 계산
similarities = cosine_similarity(query_feature, features.values)

# 유사도가 높은 상위 5개 이미지 찾기
top_5_indices = np.argsort(similarities[0])[::-1][:5]
print("Top 5 similar images:", filenames.iloc[top_5_indices].values)

from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# CSV 파일 로드
features_df = pd.read_csv(output_csv)

# 파일 이름과 특징 벡터 분리
filenames = features_df['filename']
features = features_df.drop('filename', axis=1)

# 특정 이미지의 특징 벡터 선택 (예: 첫 번째 이미지)
query_feature = features.iloc[9].values.reshape(1, -1)

# 모든 이미지와의 유사도 계산
similarities = cosine_similarity(query_feature, features.values)

# 유사도가 높은 상위 5개 이미지 찾기
top_5_indices = np.argsort(similarities[0])[::-1][:5]
top_5_filenames = filenames.iloc[top_5_indices].values

# 유사한 이미지 시각화
plt.figure(figsize=(20, 5))
for i, filename in enumerate(top_5_filenames):
    img_path = os.path.join(img_folder, filename)
    img = Image.open(img_path).convert('RGB')

    plt.subplot(1, 5, i + 1)
    plt.imshow(img)
    plt.title(f'filename {i+1}')
    plt.axis('off')

plt.show()

from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt

# CSV 파일 로드
features_df = pd.read_csv(output_csv)

# 파일 이름과 특징 벡터 분리
filenames = features_df['filename']
features = features_df.drop('filename', axis=1)

# 특정 이미지의 특징 벡터 선택 (예: 첫 번째 이미지)
query_feature = features.iloc[15].values.reshape(1, -1)

# 모든 이미지와의 유사도 계산
similarities = cosine_similarity(query_feature, features.values)

# 유사도가 높은 상위 5개 이미지 찾기
top_5_indices = np.argsort(similarities[0])[::-1][:5]
top_5_filenames = filenames.iloc[top_5_indices].values

# 파일 이름에서 'rf' 문자열 전까지 추출
def extract_title(filename):
    return filename.split('rf')[0]

# 유사한 이미지 시각화
plt.figure(figsize=(20, 5))
for i, filename in enumerate(top_5_filenames):
    img_path = os.path.join(img_folder, filename)
    img = Image.open(img_path).convert('RGB')

    plt.subplot(1, 5, i + 1)
    plt.imshow(img)
    plt.title(extract_title(filename))  # 파일 이름을 제목으로 설정
    plt.axis('off')

plt.show()

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# PCA를 사용하여 2D로 차원 축소
pca = PCA(n_components=2)
reduced_features = pca.fit_transform(features)

# 2D 시각화
plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=labels, cmap='viridis')
plt.title('PCA of Image Features')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.show()